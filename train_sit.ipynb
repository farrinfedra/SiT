{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:24.234992Z",
     "start_time": "2024-09-30T02:15:24.228145Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# the first flag below was False when we tested this script but True makes A100 training a lot faster:\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# torch.backends.cudnn.allow_tf32 = True\n",
    "# import torch.distributed as dist\n",
    "# from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.data.distributed import DistributedSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "from time import time\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from models import SiT_models\n",
    "from download import find_model\n",
    "from transport import create_transport, Sampler\n",
    "from diffusers.models import AutoencoderKL\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from train_utils import parse_transport_args\n",
    "import wandb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:27.369946Z",
     "start_time": "2024-09-30T02:15:27.367703Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def update_ema(ema_model, model, decay=0.9999):\n",
    "    \"\"\"\n",
    "    Step the EMA model towards the current model.\n",
    "    \"\"\"\n",
    "    ema_params = OrderedDict(ema_model.named_parameters())\n",
    "    model_params = OrderedDict(model.named_parameters())\n",
    "\n",
    "    for name, param in model_params.items():\n",
    "        # TODO: Consider applying only to params that require_grad to avoid small numerical changes of pos_embed\n",
    "        ema_params[name].mul_(decay).add_(param.data, alpha=1 - decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:27.374354Z",
     "start_time": "2024-09-30T02:15:27.370110Z"
    }
   },
   "outputs": [],
   "source": [
    "def requires_grad(model, flag=True):\n",
    "    \"\"\"\n",
    "    Set requires_grad flag for all parameters in a model.\n",
    "    \"\"\"\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:27.377708Z",
     "start_time": "2024-09-30T02:15:27.373691Z"
    }
   },
   "outputs": [],
   "source": [
    "# def create_logger(logging_dir):\n",
    "#     \"\"\"\n",
    "#     Create a logger that writes to a log file and stdout.\n",
    "#     \"\"\"\n",
    "#     if dist.get_rank() == 0:  # real logger\n",
    "#         logging.basicConfig(\n",
    "#             level=logging.INFO,\n",
    "#             format='[\\033[34m%(asctime)s\\033[0m] %(message)s',\n",
    "#             datefmt='%Y-%m-%d %H:%M:%S',\n",
    "#             handlers=[logging.StreamHandler(), logging.FileHandler(f\"{logging_dir}/log.txt\")]\n",
    "#         )\n",
    "#         logger = logging.getLogger(__name__)\n",
    "#     else:  # dummy logger (does nothing)\n",
    "#         logger = logging.getLogger(__name__)\n",
    "#         logger.addHandler(logging.NullHandler())\n",
    "#     return logger\n",
    "def create_logger(logging_dir):\n",
    "    \"\"\"\n",
    "    Create a logger that writes to a log file and stdout.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='[\\033[34m%(asctime)s\\033[0m] %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[logging.StreamHandler(), logging.FileHandler(f\"{logging_dir}/log.txt\")]\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:27.380933Z",
     "start_time": "2024-09-30T02:15:27.377844Z"
    }
   },
   "outputs": [],
   "source": [
    "def center_crop_arr(pil_image, image_size):\n",
    "    \"\"\"\n",
    "    Center cropping implementation from ADM.\n",
    "    https://github.com/openai/guided-diffusion/blob/8fb3ad9197f16bbc40620447b2742e13458d2831/guided_diffusion/image_datasets.py#L126\n",
    "    \"\"\"\n",
    "    while min(*pil_image.size) >= 2 * image_size:\n",
    "        pil_image = pil_image.resize(\n",
    "            tuple(x // 2 for x in pil_image.size), resample=Image.BOX\n",
    "        )\n",
    "\n",
    "    scale = image_size / min(*pil_image.size)\n",
    "    pil_image = pil_image.resize(\n",
    "        tuple(round(x * scale) for x in pil_image.size), resample=Image.BICUBIC\n",
    "    )\n",
    "\n",
    "    arr = np.array(pil_image)\n",
    "    crop_y = (arr.shape[0] - image_size) // 2\n",
    "    crop_x = (arr.shape[1] - image_size) // 2\n",
    "    return Image.fromarray(arr[crop_y: crop_y + image_size, crop_x: crop_x + image_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:27.385106Z",
     "start_time": "2024-09-30T02:15:27.382562Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dir = 'workspace'\n",
    "model_name = 'SiT-S/4'\n",
    "image_size = 32\n",
    "num_classes = 1\n",
    "ckpt = None\n",
    "device = 'mps'\n",
    "data_path = 'data'\n",
    "os.makedirs(data_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "os.makedirs(results_dir, exist_ok=True)  # Make results folder (holds all experiment subfolders)\n",
    "experiment_index = len(glob(f\"{results_dir}/*\"))\n",
    "model_string_name = model_name.replace(\"/\", \"-\")  # e.g., SiT-XL/2 --> SiT-XL-2 (for naming folders)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:27.394447Z",
     "start_time": "2024-09-30T02:15:27.385532Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "path_type = 'Linear'\n",
    "prediction = 'velocity'\n",
    "loss_weight = 1.0\n",
    "vae = 'ema'\n",
    "batch_size = 64\n",
    "cfg_scale = 10.0\n",
    "epochs = 1000\n",
    "log_every = 10\n",
    "use_wandb = True\n",
    "ckpt_every = 200\n",
    "sample_every = 50\n",
    "global_batch_size = 64"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:27.398196Z",
     "start_time": "2024-09-30T02:15:27.392480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T02:15:30.894115Z",
     "start_time": "2024-09-30T02:15:27.398821Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001B[34m2024-09-29 19:15:27\u001B[0m] Experiment directory created at workspace/003-SiT-S-4-Linear-velocity-1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:93976461) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='41.632 MB of 41.632 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "604d59364d2e43d4b354f8916801017a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train steps/sec</td><td>███▁████████████▂██▁██▁█▇▁█▇▇█████▁▇████</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>0.98497</td></tr><tr><td>train steps/sec</td><td>9.30184</td></tr><tr><td>train_step</td><td>13950</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">002-SiT-S-4-Linear-velocity-1.0</strong> at: <a href='https://wandb.ai/climate_si_team/Cifar%20SI/runs/93976461' target=\"_blank\">https://wandb.ai/climate_si_team/Cifar%20SI/runs/93976461</a><br/> View project at: <a href='https://wandb.ai/climate_si_team/Cifar%20SI' target=\"_blank\">https://wandb.ai/climate_si_team/Cifar%20SI</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 279 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240926_131721-93976461/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:93976461). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.18.1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/fedra/Desktop/SiT/wandb/run-20240929_191527-94041002</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/climate_si_team/Cifar%20SI/runs/94041002' target=\"_blank\">003-SiT-S-4-Linear-velocity-1.0</a></strong> to <a href='https://wandb.ai/climate_si_team/Cifar%20SI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/climate_si_team/Cifar%20SI' target=\"_blank\">https://wandb.ai/climate_si_team/Cifar%20SI</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/climate_si_team/Cifar%20SI/runs/94041002' target=\"_blank\">https://wandb.ai/climate_si_team/Cifar%20SI/runs/94041002</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "experiment_name = f\"{experiment_index:03d}-{model_string_name}-\" \\\n",
    "                f\"{path_type}-{prediction}-{loss_weight}\"\n",
    "experiment_dir = f\"{results_dir}/{experiment_name}\"  # Create an experiment folder\n",
    "checkpoint_dir = f\"{experiment_dir}/checkpoints\"  # Stores saved model checkpoints\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "logger = create_logger(experiment_dir)\n",
    "logger.info(f\"Experiment directory created at {experiment_dir}\")\n",
    "\n",
    "entity = 'climate_si_team' #os.environ[\"ENTITY\"]\n",
    "project = 'Cifar SI'\n",
    "#construct args\n",
    "args = argparse.Namespace(\n",
    "    model_name=model_name,\n",
    "    image_size=image_size,\n",
    "    num_classes=num_classes,\n",
    "    ckpt=ckpt,\n",
    "    device=device,\n",
    "    data_path=data_path,\n",
    "    path_type=path_type,\n",
    "    prediction=prediction,\n",
    "    loss_weight=loss_weight,\n",
    "    vae=vae,\n",
    "    batch_size=batch_size,\n",
    "    cfg_scale=cfg_scale,\n",
    "    epochs=epochs,\n",
    "    log_every=log_every,\n",
    "    use_wandb=use_wandb,\n",
    "    ckpt_every=ckpt_every,\n",
    "    sample_every=sample_every,\n",
    "    global_batch_size=global_batch_size\n",
    ")\n",
    "if use_wandb:\n",
    "    wandb_utils.initialize(args=args, entity=entity, exp_name=experiment_name, project_name=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    " # Create model:\n",
    "assert image_size % 8 == 0, \"Image size must be divisible by 8 (for the VAE encoder).\"\n",
    "latent_size = image_size #// 8\n",
    "model = SiT_models[model_name](\n",
    "    input_size=latent_size,\n",
    "    in_channels=3,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:41:55.627840Z",
     "start_time": "2024-09-30T02:41:55.329529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# Note that parameter initialization is done within the SiT constructor\n",
    "ema = deepcopy(model).to(device)  # Create an EMA of the model for use after training\n",
    "\n",
    "if ckpt is not None:\n",
    "    ckpt_path = ckpt\n",
    "    state_dict = find_model(ckpt_path)\n",
    "    model.load_state_dict(state_dict[\"model\"])\n",
    "    ema.load_state_dict(state_dict[\"ema\"])\n",
    "    opt.load_state_dict(state_dict[\"opt\"])\n",
    "    args = state_dict[\"args\"]\n",
    "\n",
    "requires_grad(ema, False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:42:08.549737Z",
     "start_time": "2024-09-30T02:42:08.526899Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001B[34m2024-09-29 19:42:11\u001B[0m] SiT Parameters: 32,542,944\n"
     ]
    }
   ],
   "source": [
    "transport = create_transport(\n",
    "        path_type,\n",
    "        prediction,\n",
    "        loss_weight,\n",
    "        # train_eps,\n",
    "        # sample_eps\n",
    "    )  # default: velocity; \n",
    "transport_sampler = Sampler(transport)\n",
    "# vae = AutoencoderKL.from_pretrained(f\"stabilityai/sd-vae-ft-{vae}\").to(device)\n",
    "logger.info(f\"SiT Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:42:11.913287Z",
     "start_time": "2024-09-30T02:42:11.906419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:42:11.913408Z",
     "start_time": "2024-09-30T02:42:11.909883Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001B[34m2024-09-29 19:42:16\u001B[0m] Dataset contains 50,000 images (data)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], inplace=True)\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "dataset = CIFAR10(root=data_path, train=True, download=True, transform=transform)\n",
    "\n",
    "# Use DistributedSampler for distributed training\n",
    "# sampler = DistributedSampler(\n",
    "#     dataset,\n",
    "#     num_replicas=dist.get_world_size(),\n",
    "#     rank=rank,\n",
    "#     shuffle=True,\n",
    "#     seed=args.global_seed\n",
    "# )\n",
    "\n",
    "# Create DataLoader\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    # num_workers=args.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "logger.info(f\"Dataset contains {len(dataset):,} images ({data_path})\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:42:16.273085Z",
     "start_time": "2024-09-30T02:42:15.321272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# Prepare models for training:\n",
    "update_ema(ema, model, decay=0)  # Ensure EMA is initialized with synced weights\n",
    "model.train()  # important! This enables embedding dropout for classifier-free guidance\n",
    "ema.eval()  # EMA model should always be in eval mode\n",
    "\n",
    "# Variables for monitoring/logging purposes:\n",
    "train_steps = 0\n",
    "log_steps = 0\n",
    "running_loss = 0\n",
    "start_time = time()\n",
    "\n",
    "# Labels to condition the model with (feel free to change):\n",
    "ys = torch.randint(1000, size=(batch_size,), device=device)\n",
    "use_cfg = cfg_scale > 1.0\n",
    "# Create sampling noise:\n",
    "n = ys.size(0)\n",
    "# zs = torch.randn(n, 4, latent_size, latent_size, device=device)\n",
    "zs = torch.randn(n, 3, latent_size, latent_size, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:44:44.672014Z",
     "start_time": "2024-09-30T02:44:44.653739Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "if use_cfg:\n",
    "    zs = torch.cat([zs, zs], 0)\n",
    "    y_null = torch.tensor([1000] * n, device=device)\n",
    "    ys = torch.cat([ys, y_null], 0)\n",
    "    sample_model_kwargs = dict(y=ys, cfg_scale=cfg_scale)\n",
    "    model_fn = ema.forward_with_cfg\n",
    "else:\n",
    "    sample_model_kwargs = dict(y=ys)\n",
    "    model_fn = ema.forward\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:44:49.415145Z",
     "start_time": "2024-09-30T02:44:49.385315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 3, 32, 32])"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:44:49.418597Z",
     "start_time": "2024-09-30T02:44:49.415588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:44:49.422316Z",
     "start_time": "2024-09-30T02:44:49.418980Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "# import PIL \n",
    "# from PIL import Image\n",
    "# \n",
    "# #show x\n",
    "# x, y = next(iter(loader))\n",
    "# x = x[0]\n",
    "# x = x.permute(1, 2, 0)\n",
    "# x = x.cpu().detach().numpy()\n",
    "# x = (x + 1) / 2\n",
    "# x = x * 255\n",
    "# x = x.astype(np.uint8)\n",
    "# img = Image.fromarray(x)\n",
    "# img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:44:49.422765Z",
     "start_time": "2024-09-30T02:44:49.421319Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# for x, y in loader:\n",
    "#     # print(x.shape)\n",
    "#     # print(x, y)\n",
    "#     #show x picture\n",
    "#     def show_image(x):\n",
    "#         x = x[0]\n",
    "#         x = x.permute(1, 2, 0)\n",
    "#         x = x.cpu().detach().numpy()\n",
    "#         x = (x + 1) / 2\n",
    "#         x = x * 255\n",
    "#         x = x.astype(np.uint8)\n",
    "#         img = Image.fromarray(x)\n",
    "#         return img\n",
    "#     \n",
    "#     img = show_image(x)\n",
    "#     latent_img = vae.encode(x.to(device)).latent_dist.sample().mul_(0.18215)\n",
    "#     # print(latent_img.latent_dist.sample())\n",
    "#     decoded_img = vae.decode( latent_img / 0.18215 ).sample\n",
    "#     decoded_image_show = show_image(decoded_img)\n",
    "#     # print(decoded_img.sample())\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:44:49.425895Z",
     "start_time": "2024-09-30T02:44:49.423189Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001B[34m2024-09-29 19:44:49\u001B[0m] Training for 1000 epochs...\n",
      "[\u001B[34m2024-09-29 19:44:49\u001B[0m] Beginning epoch 0...\n",
      "[\u001B[34m2024-09-29 19:44:53\u001B[0m] (Train Loss: 0.7534, Train Steps/Sec: 1.11\n",
      "[\u001B[34m2024-09-29 19:44:55\u001B[0m] (Train Loss: 0.6199, Train Steps/Sec: 5.94\n",
      "[\u001B[34m2024-09-29 19:44:57\u001B[0m] (Train Loss: 0.5110, Train Steps/Sec: 6.01\n",
      "[\u001B[34m2024-09-29 19:44:58\u001B[0m] (Train Loss: 0.4768, Train Steps/Sec: 6.05\n",
      "[\u001B[34m2024-09-29 19:45:00\u001B[0m] (Train Loss: 0.4293, Train Steps/Sec: 6.03\n",
      "[\u001B[34m2024-09-29 19:45:00\u001B[0m] Generating EMA samples...\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Tried to log to step 10 that is less than the current step 50. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Tried to log to step 20 that is less than the current step 50. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Tried to log to step 30 that is less than the current step 50. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Tried to log to step 40 that is less than the current step 50. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "[\u001B[34m2024-09-29 19:45:23\u001B[0m] Generating EMA samples done.\n",
      "[\u001B[34m2024-09-29 19:45:25\u001B[0m] (Train Loss: 0.4248, Train Steps/Sec: 0.39\n",
      "[\u001B[34m2024-09-29 19:45:27\u001B[0m] (Train Loss: 0.4132, Train Steps/Sec: 5.64\n",
      "[\u001B[34m2024-09-29 19:45:29\u001B[0m] (Train Loss: 0.3839, Train Steps/Sec: 5.53\n",
      "[\u001B[34m2024-09-29 19:45:31\u001B[0m] (Train Loss: 0.3986, Train Steps/Sec: 5.50\n",
      "[\u001B[34m2024-09-29 19:45:32\u001B[0m] (Train Loss: 0.3917, Train Steps/Sec: 5.50\n",
      "[\u001B[34m2024-09-29 19:45:32\u001B[0m] Generating EMA samples...\n",
      "[\u001B[34m2024-09-29 19:45:58\u001B[0m] Generating EMA samples done.\n",
      "[\u001B[34m2024-09-29 19:46:01\u001B[0m] (Train Loss: 0.3661, Train Steps/Sec: 0.35\n",
      "[\u001B[34m2024-09-29 19:46:03\u001B[0m] (Train Loss: 0.3756, Train Steps/Sec: 4.99\n",
      "[\u001B[34m2024-09-29 19:46:05\u001B[0m] (Train Loss: 0.3726, Train Steps/Sec: 5.04\n",
      "[\u001B[34m2024-09-29 19:46:07\u001B[0m] (Train Loss: 0.3661, Train Steps/Sec: 5.18\n",
      "[\u001B[34m2024-09-29 19:46:09\u001B[0m] (Train Loss: 0.3576, Train Steps/Sec: 5.50\n",
      "[\u001B[34m2024-09-29 19:46:09\u001B[0m] Generating EMA samples...\n",
      "[\u001B[34m2024-09-29 19:46:35\u001B[0m] Generating EMA samples done.\n",
      "[\u001B[34m2024-09-29 19:46:37\u001B[0m] (Train Loss: 0.3431, Train Steps/Sec: 0.36\n",
      "[\u001B[34m2024-09-29 19:46:39\u001B[0m] (Train Loss: 0.3503, Train Steps/Sec: 4.98\n",
      "[\u001B[34m2024-09-29 19:46:40\u001B[0m] (Train Loss: 0.3510, Train Steps/Sec: 5.29\n",
      "[\u001B[34m2024-09-29 19:46:42\u001B[0m] (Train Loss: 0.3450, Train Steps/Sec: 5.36\n",
      "[\u001B[34m2024-09-29 19:46:44\u001B[0m] (Train Loss: 0.3516, Train Steps/Sec: 5.39\n",
      "[\u001B[34m2024-09-29 19:46:45\u001B[0m] Saved checkpoint to workspace/003-SiT-S-4-Linear-velocity-1.0/checkpoints/0000200.pt\n",
      "[\u001B[34m2024-09-29 19:46:45\u001B[0m] Generating EMA samples...\n",
      "[\u001B[34m2024-09-29 19:47:11\u001B[0m] Generating EMA samples done.\n",
      "[\u001B[34m2024-09-29 19:47:14\u001B[0m] (Train Loss: 0.3531, Train Steps/Sec: 0.33\n",
      "[\u001B[34m2024-09-29 19:47:16\u001B[0m] (Train Loss: 0.3466, Train Steps/Sec: 5.92\n",
      "[\u001B[34m2024-09-29 19:47:18\u001B[0m] (Train Loss: 0.3407, Train Steps/Sec: 5.46\n",
      "[\u001B[34m2024-09-29 19:47:20\u001B[0m] (Train Loss: 0.3470, Train Steps/Sec: 4.63\n",
      "[\u001B[34m2024-09-29 19:47:22\u001B[0m] (Train Loss: 0.3337, Train Steps/Sec: 4.85\n",
      "[\u001B[34m2024-09-29 19:47:22\u001B[0m] Generating EMA samples...\n",
      "[\u001B[34m2024-09-29 19:47:48\u001B[0m] Generating EMA samples done.\n",
      "[\u001B[34m2024-09-29 19:47:51\u001B[0m] (Train Loss: 0.3509, Train Steps/Sec: 0.34\n",
      "[\u001B[34m2024-09-29 19:47:53\u001B[0m] (Train Loss: 0.3336, Train Steps/Sec: 5.64\n",
      "[\u001B[34m2024-09-29 19:47:55\u001B[0m] (Train Loss: 0.3207, Train Steps/Sec: 5.15\n",
      "[\u001B[34m2024-09-29 19:47:57\u001B[0m] (Train Loss: 0.3243, Train Steps/Sec: 4.85\n",
      "[\u001B[34m2024-09-29 19:47:59\u001B[0m] (Train Loss: 0.3275, Train Steps/Sec: 5.06\n",
      "[\u001B[34m2024-09-29 19:47:59\u001B[0m] Generating EMA samples...\n",
      "[\u001B[34m2024-09-29 19:48:25\u001B[0m] Generating EMA samples done.\n",
      "[\u001B[34m2024-09-29 19:48:27\u001B[0m] (Train Loss: 0.3170, Train Steps/Sec: 0.36\n",
      "[\u001B[34m2024-09-29 19:48:29\u001B[0m] (Train Loss: 0.3143, Train Steps/Sec: 5.90\n",
      "[\u001B[34m2024-09-29 19:48:31\u001B[0m] (Train Loss: 0.3230, Train Steps/Sec: 4.99\n",
      "[\u001B[34m2024-09-29 19:48:33\u001B[0m] (Train Loss: 0.3233, Train Steps/Sec: 5.15\n",
      "[\u001B[34m2024-09-29 19:48:35\u001B[0m] (Train Loss: 0.3156, Train Steps/Sec: 4.99\n",
      "[\u001B[34m2024-09-29 19:48:35\u001B[0m] Generating EMA samples...\n",
      "[\u001B[34m2024-09-29 19:49:00\u001B[0m] Generating EMA samples done.\n",
      "[\u001B[34m2024-09-29 19:49:02\u001B[0m] (Train Loss: 0.2959, Train Steps/Sec: 0.37\n",
      "[\u001B[34m2024-09-29 19:49:04\u001B[0m] (Train Loss: 0.3073, Train Steps/Sec: 5.31\n",
      "[\u001B[34m2024-09-29 19:49:05\u001B[0m] (Train Loss: 0.3185, Train Steps/Sec: 5.38\n",
      "[\u001B[34m2024-09-29 19:49:07\u001B[0m] (Train Loss: 0.3018, Train Steps/Sec: 5.21\n",
      "[\u001B[34m2024-09-29 19:49:09\u001B[0m] (Train Loss: 0.3140, Train Steps/Sec: 5.17\n",
      "[\u001B[34m2024-09-29 19:49:10\u001B[0m] Saved checkpoint to workspace/003-SiT-S-4-Linear-velocity-1.0/checkpoints/0000400.pt\n",
      "[\u001B[34m2024-09-29 19:49:10\u001B[0m] Generating EMA samples...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[124], line 64\u001B[0m\n\u001B[1;32m     62\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating EMA samples...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     63\u001B[0m sample_fn \u001B[38;5;241m=\u001B[39m transport_sampler\u001B[38;5;241m.\u001B[39msample_ode() \u001B[38;5;66;03m# default to ode sampling\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m samples \u001B[38;5;241m=\u001B[39m sample_fn(zs, model_fn, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msample_model_kwargs)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# dist.barrier()\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cfg: \u001B[38;5;66;03m#remove null samples\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/SiT/transport/integrators.py:115\u001B[0m, in \u001B[0;36mode.sample\u001B[0;34m(self, x, model, **model_kwargs)\u001B[0m\n\u001B[1;32m    108\u001B[0m rtol \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrtol] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(x) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrtol]\n\u001B[1;32m    109\u001B[0m \u001B[38;5;66;03m#cast to float32\u001B[39;00m\n\u001B[1;32m    110\u001B[0m \n\u001B[1;32m    111\u001B[0m \u001B[38;5;66;03m# with th.autocast(device_type='mps', dtype=th.float32):\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;66;03m#move x, t to cpu\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# x = x.cpu()\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;66;03m# t = t.cpu()\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m samples \u001B[38;5;241m=\u001B[39m odeint(\n\u001B[1;32m    116\u001B[0m     _fn,\n\u001B[1;32m    117\u001B[0m     x,\n\u001B[1;32m    118\u001B[0m     t,\n\u001B[1;32m    119\u001B[0m     method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrk4\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;66;03m#self.sampler_type, #'rk4', #self.sampler_type,\u001B[39;00m\n\u001B[1;32m    120\u001B[0m     atol\u001B[38;5;241m=\u001B[39matol,\n\u001B[1;32m    121\u001B[0m     rtol\u001B[38;5;241m=\u001B[39mrtol\n\u001B[1;32m    122\u001B[0m )\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# samples = samples.to(device)\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m samples\n",
      "File \u001B[0;32m~/miniconda3/envs/SiT/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py:79\u001B[0m, in \u001B[0;36modeint\u001B[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001B[0m\n\u001B[1;32m     76\u001B[0m solver \u001B[38;5;241m=\u001B[39m SOLVERS[method](func\u001B[38;5;241m=\u001B[39mfunc, y0\u001B[38;5;241m=\u001B[39my0, rtol\u001B[38;5;241m=\u001B[39mrtol, atol\u001B[38;5;241m=\u001B[39matol, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 79\u001B[0m     solution \u001B[38;5;241m=\u001B[39m solver\u001B[38;5;241m.\u001B[39mintegrate(t)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     81\u001B[0m     event_t, solution \u001B[38;5;241m=\u001B[39m solver\u001B[38;5;241m.\u001B[39mintegrate_until_event(t[\u001B[38;5;241m0\u001B[39m], event_fn)\n",
      "File \u001B[0;32m~/miniconda3/envs/SiT/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py:114\u001B[0m, in \u001B[0;36mFixedGridODESolver.integrate\u001B[0;34m(self, t)\u001B[0m\n\u001B[1;32m    112\u001B[0m dt \u001B[38;5;241m=\u001B[39m t1 \u001B[38;5;241m-\u001B[39m t0\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\u001B[38;5;241m.\u001B[39mcallback_step(t0, y0, dt)\n\u001B[0;32m--> 114\u001B[0m dy, f0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_step_func(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc, t0, dt, t1, y0)\n\u001B[1;32m    115\u001B[0m y1 \u001B[38;5;241m=\u001B[39m y0 \u001B[38;5;241m+\u001B[39m dy\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m j \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(t) \u001B[38;5;129;01mand\u001B[39;00m t1 \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m t[j]:\n",
      "File \u001B[0;32m~/miniconda3/envs/SiT/lib/python3.12/site-packages/torchdiffeq/_impl/fixed_grid.py:29\u001B[0m, in \u001B[0;36mRK4._step_func\u001B[0;34m(self, func, t0, dt, t1, y0)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_step_func\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, t0, dt, t1, y0):\n\u001B[1;32m     28\u001B[0m     f0 \u001B[38;5;241m=\u001B[39m func(t0, y0, perturb\u001B[38;5;241m=\u001B[39mPerturb\u001B[38;5;241m.\u001B[39mNEXT \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperturb \u001B[38;5;28;01melse\u001B[39;00m Perturb\u001B[38;5;241m.\u001B[39mNONE)\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m rk4_alt_step_func(func, t0, dt, t1, y0, f0\u001B[38;5;241m=\u001B[39mf0, perturb\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperturb), f0\n",
      "File \u001B[0;32m~/miniconda3/envs/SiT/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:113\u001B[0m, in \u001B[0;36mrk4_alt_step_func\u001B[0;34m(func, t0, dt, t1, y0, f0, perturb)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m k1 \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    112\u001B[0m     k1 \u001B[38;5;241m=\u001B[39m func(t0, y0, perturb\u001B[38;5;241m=\u001B[39mPerturb\u001B[38;5;241m.\u001B[39mNEXT \u001B[38;5;28;01mif\u001B[39;00m perturb \u001B[38;5;28;01melse\u001B[39;00m Perturb\u001B[38;5;241m.\u001B[39mNONE)\n\u001B[0;32m--> 113\u001B[0m k2 \u001B[38;5;241m=\u001B[39m func(t0 \u001B[38;5;241m+\u001B[39m dt \u001B[38;5;241m*\u001B[39m _one_third, y0 \u001B[38;5;241m+\u001B[39m dt \u001B[38;5;241m*\u001B[39m k1 \u001B[38;5;241m*\u001B[39m _one_third)\n\u001B[1;32m    114\u001B[0m k3 \u001B[38;5;241m=\u001B[39m func(t0 \u001B[38;5;241m+\u001B[39m dt \u001B[38;5;241m*\u001B[39m _two_thirds, y0 \u001B[38;5;241m+\u001B[39m dt \u001B[38;5;241m*\u001B[39m (k2 \u001B[38;5;241m-\u001B[39m k1 \u001B[38;5;241m*\u001B[39m _one_third))\n\u001B[1;32m    115\u001B[0m k4 \u001B[38;5;241m=\u001B[39m func(t1, y0 \u001B[38;5;241m+\u001B[39m dt \u001B[38;5;241m*\u001B[39m (k1 \u001B[38;5;241m-\u001B[39m k2 \u001B[38;5;241m+\u001B[39m k3), perturb\u001B[38;5;241m=\u001B[39mPerturb\u001B[38;5;241m.\u001B[39mPREV \u001B[38;5;28;01mif\u001B[39;00m perturb \u001B[38;5;28;01melse\u001B[39;00m Perturb\u001B[38;5;241m.\u001B[39mNONE)\n",
      "File \u001B[0;32m~/miniconda3/envs/SiT/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/SiT/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/SiT/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001B[0m, in \u001B[0;36m_PerturbFunc.forward\u001B[0;34m(self, t, y, perturb)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# Do nothing.\u001B[39;00m\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_func(t, y)\n",
      "File \u001B[0;32m~/Desktop/SiT/transport/integrators.py:102\u001B[0m, in \u001B[0;36mode.sample.<locals>._fn\u001B[0;34m(t, x)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_fn\u001B[39m(t, x):\n\u001B[0;32m--> 102\u001B[0m     t \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mones(x[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;241m*\u001B[39m t \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m th\u001B[38;5;241m.\u001B[39mones(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;241m*\u001B[39m t\n\u001B[1;32m    103\u001B[0m     model_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrift(x, t, model, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_output\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "logger.info(f\"Training for {epochs} epochs...\")\n",
    "for epoch in range(epochs):\n",
    "    # sampler.set_epoch(epoch)\n",
    "    logger.info(f\"Beginning epoch {epoch}...\")\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # with torch.no_grad():\n",
    "            # Map input images to latent space + normalize latents:\n",
    "            # x = vae.encode(x).latent_dist.sample().mul_(0.18215)\n",
    "        model_kwargs = dict(y=y)\n",
    "        loss_dict = transport.training_losses(model, x, model_kwargs)\n",
    "        loss = loss_dict[\"loss\"].mean()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        update_ema(ema, model)\n",
    "\n",
    "        # Log loss values:\n",
    "        running_loss += loss.item()\n",
    "        log_steps += 1\n",
    "        train_steps += 1\n",
    "        \n",
    "        if train_steps % log_every == 0:\n",
    "            # Measure training speed:\n",
    "            # torch.cuda.synchronize()\n",
    "            end_time = time()\n",
    "            steps_per_sec = log_steps / (end_time - start_time)\n",
    "            # # Reduce loss history over all processes:\n",
    "            avg_loss = torch.tensor(running_loss / log_steps, device=device)\n",
    "            # dist.all_reduce(avg_loss, op=dist.ReduceOp.SUM)\n",
    "            # avg_loss = avg_loss.item() / dist.get_world_size()\n",
    "            # logger.info(f\"(step={train_steps:07d}) Train Loss: {avg_loss:.4f}, Train Steps/Sec: {steps_per_sec:.2f}\")\n",
    "            logger.info(f\"(Train Loss: {avg_loss:.4f}, Train Steps/Sec: {steps_per_sec:.2f}\")\n",
    "            \n",
    "            if use_wandb:\n",
    "              \n",
    "                wandb_utils.log(\n",
    "                    { \"train loss\": avg_loss, \"train steps/sec\": steps_per_sec },\n",
    "                    step=train_steps\n",
    "                )\n",
    "            # Reset monitoring variables:\n",
    "            running_loss = 0\n",
    "            log_steps = 0\n",
    "            start_time = time()\n",
    "\n",
    "        # Save SiT checkpoint:\n",
    "        if train_steps % ckpt_every == 0 and train_steps > 0:\n",
    "            # if rank == 0:\n",
    "            checkpoint = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"ema\": ema.state_dict(),\n",
    "                \"opt\": opt.state_dict(),\n",
    "                # \"args\": args\n",
    "            }\n",
    "            checkpoint_path = f\"{checkpoint_dir}/{train_steps:07d}.pt\"\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "            # dist.barrier()\n",
    "        \n",
    "        if train_steps % sample_every == 0 and train_steps > 0:\n",
    "            logger.info(\"Generating EMA samples...\")\n",
    "            sample_fn = transport_sampler.sample_ode() # default to ode sampling\n",
    "            samples = sample_fn(zs, model_fn, **sample_model_kwargs)[-1]\n",
    "            # dist.barrier()\n",
    "\n",
    "            if use_cfg: #remove null samples\n",
    "                samples, _ = samples.chunk(2, dim=0)\n",
    "            # samples = vae.decode(samples / 0.18215).sample\n",
    "            # out_samples = torch.zeros((global_batch_size, 3, image_size, image_size), device=device)\n",
    "            out_samples = samples\n",
    "            \n",
    "            if use_wandb:\n",
    "                wandb_utils.log_image(out_samples, train_steps)\n",
    "            logging.info(\"Generating EMA samples done.\")\n",
    "\n",
    "model.eval()  # important! This disables randomized embedding dropout\n",
    "# do any sampling/FID calculation/etc. with ema (or model) in eval mode ...\n",
    "\n",
    "logger.info(\"Done!\")\n",
    "    # cleanup()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T02:49:24.906936Z",
     "start_time": "2024-09-30T02:44:49.425043Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-26T20:54:45.911514Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T20:54:45.913661Z",
     "start_time": "2024-09-26T20:54:45.913420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T04:10:09.290358Z",
     "start_time": "2024-09-27T04:10:09.282100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T04:10:12.158793Z",
     "start_time": "2024-09-27T04:10:12.155438Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
